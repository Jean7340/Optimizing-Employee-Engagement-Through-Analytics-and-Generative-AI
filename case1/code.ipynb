{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "courses_df = pd.read_csv(\"/Users/liuzhiying/Desktop/GBA424_Analytics Design and Application/coursework/case1/nls_courses.csv\")\n",
    "employees_df = pd.read_csv(\"/Users/liuzhiying/Desktop/GBA424_Analytics Design and Application/coursework/case1/nls_employees.csv\")\n",
    "local_offices_df = pd.read_csv(\"/Users/liuzhiying/Desktop/GBA424_Analytics Design and Application/coursework/case1/nls_local_offices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m enrollment_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/liuzhiying/Desktop/GBA424_Analytics Design and Application/coursework/case1/nls_enrollment.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      2\u001b[0m                                 encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      3\u001b[0m                                 on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "enrollment_df = pd.read_csv(\"/Users/liuzhiying/Desktop/GBA424_Analytics Design and Application/coursework/case1/nls_enrollment.csv\", \n",
    "                                encoding='ISO-8859-1', \n",
    "                                on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Course_ID                                      Course_Title  \\\n",
      "0        101                     Logistics Software Essentials   \n",
      "1        102                                     Intro to NERP   \n",
      "2        103       Advanced Warehouse Management Systems (WMS)   \n",
      "3        104  Advanced Transportation Management Systems (TMS)   \n",
      "4        105              Supply Chain Optimization Strategies   \n",
      "\n",
      "                                  Course_Description  Hours  \\\n",
      "0  An introductory course covering the basics of ...      8   \n",
      "1  A comprehensive overview of Nexus Enterprise R...      6   \n",
      "2  An in-depth course on advanced features of WMS...     10   \n",
      "3  An in-depth course on optimizing transportatio...     10   \n",
      "4  An advanced course focused on designing and im...     24   \n",
      "\n",
      "                                  Materials  \n",
      "0  Course Handbook, TMS/WMS Software Access  \n",
      "1        NERP Software Access, Course Notes  \n",
      "2              Advanced WMS Software Manual  \n",
      "3   TMS Optimization Guide, Software Access  \n",
      "4   Supply Chain Case Studies, Course Notes  \n",
      "        Course_ID     Hours\n",
      "count   10.000000  10.00000\n",
      "mean   520.500000  11.20000\n",
      "std    441.288329   5.49343\n",
      "min    101.000000   6.00000\n",
      "25%    103.250000   8.00000\n",
      "50%    503.000000  10.00000\n",
      "75%    903.500000  13.75000\n",
      "max    992.000000  24.00000\n"
     ]
    }
   ],
   "source": [
    "print(courses_df.head())\n",
    "print(courses_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Employee_ID  Office_ID First_Name Last_Name Job_Title Pay_Grade Department  \\\n",
      "0       128371         23        XXX       XXX       XXX       XXX        XXX   \n",
      "1       128372         30        XXX       XXX       XXX       XXX        XXX   \n",
      "2       128376          8        XXX       XXX       XXX       XXX        XXX   \n",
      "3       128383         27        XXX       XXX       XXX       XXX        XXX   \n",
      "4       128445         46        XXX       XXX       XXX       XXX        XXX   \n",
      "\n",
      "  Supervisor_ID Hire_Date Employment_Status Termination_Date  \n",
      "0           XXX       XXX               XXX              XXX  \n",
      "1           XXX       XXX               XXX              XXX  \n",
      "2           XXX       XXX               XXX              XXX  \n",
      "3           XXX       XXX               XXX              XXX  \n",
      "4           XXX       XXX               XXX              XXX  \n",
      "         Employee_ID     Office_ID\n",
      "count   25119.000000  25119.000000\n",
      "mean   499607.679008     23.568096\n",
      "std    214895.222653     12.815055\n",
      "min    128371.000000      1.000000\n",
      "25%    313620.500000     12.000000\n",
      "50%    498608.000000     25.000000\n",
      "75%    684650.500000     33.000000\n",
      "max    874217.000000     46.000000\n"
     ]
    }
   ],
   "source": [
    "print(employees_df.head())\n",
    "print(employees_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Office_ID  Regional_Center_ID          Office_Name      Address_Line1  \\\n",
      "0          1                 101          Miami Local       79 Trade Ave   \n",
      "1          2                 101      Baltimore Local   4 Harborfront Dr   \n",
      "2          3                 101       New York Local        500 5th Ave   \n",
      "3          4                 102        Seattle Local    2884 Fordham St   \n",
      "4          5                 102  San Francisco Local  101 Pino Verde Dr   \n",
      "\n",
      "            City State_Province Postal_Code Country    Phone_Number  \\\n",
      "0          Miami             FL       33101     USA  1-305-555-1234   \n",
      "1      Baltimore             MD       21201     USA  1-410-555-2345   \n",
      "2       New York             NY       10001     USA  1-212-555-7890   \n",
      "3        Seattle             WA       98101     USA  1-206-555-3456   \n",
      "4  San Francisco             CA       94101     USA  1-415-555-4567   \n",
      "\n",
      "              Email_Address Office_Manager Opening_Date     Time_Zone  \\\n",
      "0      miami.office@nls.com  Anu Prabhakar    3/15/2010  Eastern Time   \n",
      "1  baltimore.office@nls.com    Robert Chen    6/20/2012  Eastern Time   \n",
      "2         ny.office@nls.com       John Doe    2/10/2010  Eastern Time   \n",
      "3    seattle.office@nls.com     Linda Park    11/5/2008  Pacific Time   \n",
      "4         sf.office@nls.com      Donna Fox     9/1/2009  Pacific Time   \n",
      "\n",
      "   Latitude  Longitude  \n",
      "0   25.7617   -80.1918  \n",
      "1   39.2904   -76.6122  \n",
      "2   40.7128   -74.0060  \n",
      "3   47.6062  -122.3321  \n",
      "4   37.7749  -122.4194  \n",
      "       Office_ID  Regional_Center_ID   Latitude   Longitude\n",
      "count  46.000000           46.000000  46.000000   46.000000\n",
      "mean   23.500000          249.934783  26.333826  -12.579209\n",
      "std    13.422618          112.797045  22.760272   84.412351\n",
      "min     1.000000          101.000000 -34.603700 -122.419400\n",
      "25%    12.250000          128.250000  13.967100  -79.476675\n",
      "50%    23.500000          252.000000  32.641300  -26.446800\n",
      "75%    34.750000          303.000000  43.321100   59.911325\n",
      "max    46.000000          403.000000  53.349800  139.691700\n"
     ]
    }
   ],
   "source": [
    "print(local_offices_df.head())\n",
    "print(local_offices_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enrollment_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(enrollment_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(enrollment_df\u001b[38;5;241m.\u001b[39mdescribe())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enrollment_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(enrollment_df.head())\n",
    "print(enrollment_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enrollment_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m enrollment_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCourse\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCourse_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m enrollment_course_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(enrollment_df, courses_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCourse_ID\u001b[39m\u001b[38;5;124m\"\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(enrollment_course_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'enrollment_df' is not defined"
     ]
    }
   ],
   "source": [
    "enrollment_df.rename(columns={\"Course\": \"Course_ID\"}, inplace=True)\n",
    "\n",
    "enrollment_course_df = pd.merge(enrollment_df, courses_df, on=\"Course_ID\", how=\"left\")\n",
    "print(enrollment_course_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
